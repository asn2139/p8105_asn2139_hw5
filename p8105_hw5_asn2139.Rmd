---
title: "Homework 5"
author: Akanksha Nalatwad
output: html_document
---


```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
homicide_df=
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state= str_c(city, state, sep = "_"),
    resolved= case_when(
      disposition=="Closed without arrest"~ "unsolved",
      disposition=="Open/No arrest"       ~ "unsolved",
      disposition== "Closed by arrest"      ~"solved"
      )
  ) %>% 
  select(city_state,resolved) %>% 
  filter(city_state !="Tulsa_AL")
```
Let's look at this a bit

```{r}
aggregate_df=
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total=n(),
    hom_unsolved= sum(resolved=="unsolved")
  )
  
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter (city_state=="Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter (city_state=="Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

 
Try to iterate.....

```{r}
results_df=
aggregate_df %>% 
  mutate(
    prop_tests= map2(.x=hom_unsolved, .y=hom_total, ~prop.test(x=.x, n=.y)),
    tidy_tests= map (.x= prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```


```{r}
results_df %>% 
  mutate(city_state=fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x=city_state, y=estimate))+
  geom_point()+
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high))+
  theme(axis.text.x= element_text (angle=90, vjust=0.5, hjust=1))
```
## Problem 2

Data Mapping and Tidying


```{r}
path_df=
tibble(
  path= list.files("lda_data")
) %>% 
  mutate(path=str_c("lda_data/", path),
         path_2=path,
         data=map(path, read_csv)) %>% 
  separate(col=path_2, into=c("path_a", "path_b"), sep=9, remove=T) %>% 
  separate(col=path_b, into= c("arm", "id_number", sep=3)) %>% 
  select(-path_a,-c(5)) %>% 
  mutate(
  arm=str_replace(arm,"exp","Experimental"), 
  arm=str_replace(arm, "con", "Control")) %>% 
  within(Arm_ID <- paste(arm, id_number, sep='_')) %>% 
  select(-id_number) %>% 
  unnest(data) %>%
 pivot_longer(week_1:week_8,
              names_to="week_number",
              values_to="weekly_observation"
            ) %>% 
  mutate(
    week_number= str_replace(week_number, "week_", "")
  )
```

## Spaghetti Plot
```{r}
plot_p=
ggplot(data = path_df, aes(x = week_number, y = weekly_observation, group = Arm_ID))+
   geom_line(aes(linetype=arm))
```
Comments on Plot:

It looks like generally the experimental patients had higher weekly observations than the control patients. In general, experimental patients showed less dramatic differences in observations by week compared to control patients. Additionally, it looks like the experimental patients' observations increased over time compared to control patients who fluctuated around the same number of observations. 

## Problem 3

Function

```{r}

library(broom)
n=30
sigma=5
mu=c(0,1,2,3,4,5,6)
mean=mu
sd=sigma

sample = function(n, mean, sd){
samp_data = tibble(
samp = rnorm(n, mean, sd)
)

samp_result = nest(samp_data) %>%
mutate(
  t_test = map(.x = data, ~{tidy(t.test(x = .x,mu=0, alternative = 'two.sided', paired = FALSE, conf.level = 0.95))})) %>% 
unnest(t_test)

return(samp_result)
}

```

```{r}
mean_list =
  list(
    "mean_0" = 0,
    "mean_1" = 1,
    "mean_2" = 2,
    "mean_3" = 3,
    "mean_4" = 4,
    "mean_5" = 5,
    "mean_6" = 6
    )

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(10, sample(10, mean_list[[i]], 5)) %>% 
  bind_rows()
}

sim_results = 
  tibble(mu = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x =mu, ~rerun(5000, sample(10, mean_list[[i]], 5))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(mu,p.value, estimate) %>% 
  mutate(
    hyp_test=ifelse(p.value > 0.05, "fail_to_reject", "reject")
  )

```

## Plot 1: Effect Size and Power

```{r}
plot1_p=
sim_results %>% 
 filter(hyp_test=="reject") %>% 
  group_by(mu) %>% 
  summarize(
    reject_obs= n()
  ) %>% 
  mutate(
    prop= reject_obs/35000
  ) %>% 
  ggplot(aes(x=mu, y= prop))+
  geom_point()
```

Comments on Plot: It looks like this plot follows a chunk of a sinusoidal function. It seems to have a repeating peaks and valleys as mu increases. However, it is importan to note that the proportions of rejected observations across the board are extremely small and not that different. It's range is 0.131-0.132. 

## Plot 2: True Mu vs Estimated Mu

```{r}
plot2_p=
sim_results %>% 
  group_by(mu) %>% 
  summarize(avg_mu= mean(estimate)) %>% 
  ggplot(aes(x=mu,y=avg_mu))+geom_point()+geom_line()


```


## Plot3: True Mu vs Estimated Mu, Only in Examples For Which Null Was Rejected

```{r}
plot3_p=
sim_results %>% 
  filter(hyp_test=="reject") %>% 
  group_by(mu) %>% 
  summarize(avg_mu= mean(estimate)) %>% 
  ggplot(aes(x=mu,y=avg_mu))+geom_point()+geom_line() 
```

Reflection: 
It does not look like the sample average of μ̂ across tests for which the null is rejected approximatel isy equal to the true value of μ because the sample size is so small and the standard deviation was so large. Smaller sample sizes lead to smaller amounts of power in a study/test. Additionally, larger standard deviations also result in smaller power sizes. Both of these effects lead to less likely chance that the a null hypothesis will be correctly rejected.
